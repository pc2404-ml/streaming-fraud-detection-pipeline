{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d4e622-3793-435a-907c-fc9fa3f3c62d",
   "metadata": {},
   "source": [
    "# Feature Engineering on Credit Card Fraud Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af4934b0-e9a8-4840-aa0b-80cf361dc858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63369149-35d2-4b08-93cf-e03ba680506d",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9b9c559-35e8-441c-a58c-5644a5613198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (1000, 16)\n",
      "Original columns: ['username', 'full_name', 'email', 'phone', 'transaction_amount', 'merchant', 'card_last_4', 'card_provider', 'country', 'address', 'city', 'state', 'zipcode', 'transaction_date', 'transaction_hour', 'is_fraud']\n"
     ]
    }
   ],
   "source": [
    "file=glob.glob(\"../output/training_data/part-*.csv\")[0]\n",
    "# Load your data\n",
    "df = pd.read_csv(file)  \n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Original columns: {list(df.columns)}\")\n",
    "\n",
    "# Create a copy for feature engineering\n",
    "df_features = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a39e2-19dd-443b-acb4-bd92bba0d70b",
   "metadata": {},
   "source": [
    "## Amount-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26ae7123-4b8f-44d4-ba50-428a3934426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CREATING AMOUNT-BASED FEATURES\n",
      "----------------------------------------\n",
      "Created: amount_category\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n CREATING AMOUNT-BASED FEATURES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# Amount categories\n",
    "df_features['amount_category'] = pd.cut(df_features['transaction_amount'], \n",
    "                                      bins=[0, 50, 200, 500, 1000, 2000, float('inf')], \n",
    "                                      labels=['very_low', 'low', 'medium', 'high', 'very_high', 'extreme'])\n",
    "print(\"Created: amount_category\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88673d3f-6257-44e7-8ff9-326eceffc1c2",
   "metadata": {},
   "source": [
    "## Time-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a9e808a-573c-45e6-b7ae-7c41722307c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATING TIME-BASED FEATURES\n",
      "----------------------------------------\n",
      "Created: is_night, is_morning, is_afternoon, is_evening\n",
      "Created: is_business_hours, is_late_night, is_peak_hours\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nCREATING TIME-BASED FEATURES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Hour categories\n",
    "df_features['is_night'] = df_features['transaction_hour'].apply(lambda x: 1 if x <= 6 or x >= 22 else 0)\n",
    "df_features['is_morning'] = df_features['transaction_hour'].apply(lambda x: 1 if 6 < x <= 12 else 0)\n",
    "df_features['is_afternoon'] = df_features['transaction_hour'].apply(lambda x: 1 if 12 < x <= 18 else 0)\n",
    "df_features['is_evening'] = df_features['transaction_hour'].apply(lambda x: 1 if 18 < x < 22 else 0)\n",
    "print(\"Created: is_night, is_morning, is_afternoon, is_evening\")\n",
    "\n",
    "# Business hours\n",
    "df_features['is_business_hours'] = df_features['transaction_hour'].apply(lambda x: 1 if 9 <= x <= 17 else 0)\n",
    "df_features['is_late_night'] = df_features['transaction_hour'].apply(lambda x: 1 if x <= 5 or x >= 23 else 0)\n",
    "df_features['is_peak_hours'] = df_features['transaction_hour'].apply(lambda x: 1 if x in [12, 13, 18, 19, 20] else 0)\n",
    "print(\"Created: is_business_hours, is_late_night, is_peak_hours\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12090114-b974-4536-a875-fbe979a33ae9",
   "metadata": {},
   "source": [
    "## Location-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8131b8f3-0ae9-4f2c-a2d4-72a1bcdab5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CREATING LOCATION-BASED FEATURES\n",
      "----------------------------------------\n",
      "Created: is_international\n",
      "Created: country_risk_score\n",
      "Created: state_risk_score\n",
      "Created: is_major_city\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n CREATING LOCATION-BASED FEATURES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# International transaction flag\n",
    "df_features['is_international'] = (df_features['country'] != 'United States').astype(int)\n",
    "print(\"Created: is_international\")\n",
    "\n",
    "# Country risk score (based on fraud rate by country)\n",
    "country_fraud_rate = df_features.groupby('country')['is_fraud'].mean()\n",
    "df_features['country_risk_score'] = df_features['country'].map(country_fraud_rate)\n",
    "print(\"Created: country_risk_score\")\n",
    "\n",
    "# State features (if US)\n",
    "if 'state' in df_features.columns:\n",
    "    state_fraud_rate = df_features.groupby('state')['is_fraud'].mean()\n",
    "    df_features['state_risk_score'] = df_features['state'].map(state_fraud_rate)\n",
    "    print(\"Created: state_risk_score\")\n",
    "\n",
    "# Major cities flag (you can customize this list)\n",
    "major_cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia', \n",
    "                'San Antonio', 'San Diego', 'Dallas', 'San Jose', 'Austin', 'Jacksonville']\n",
    "if 'city' in df_features.columns:\n",
    "    df_features['is_major_city'] = df_features['city'].isin(major_cities).astype(int)\n",
    "    print(\"Created: is_major_city\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800541cf-616b-401c-b021-89e525ecd290",
   "metadata": {},
   "source": [
    "## Merchant-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9b83ba63-7454-447c-8f81-21b6001be0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATING MERCHANT-BASED FEATURES\n",
      "----------------------------------------\n",
      " Created: merchant_risk_score\n",
      " Created: merchant_volume\n",
      " Created: is_high_risk_merchant\n",
      " Created: merchant_avg_amount, amount_vs_merchant_avg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nCREATING MERCHANT-BASED FEATURES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Merchant risk score\n",
    "merchant_fraud_rate = df_features.groupby('merchant')['is_fraud'].mean()\n",
    "df_features['merchant_risk_score'] = df_features['merchant'].map(merchant_fraud_rate)\n",
    "print(\" Created: merchant_risk_score\")\n",
    "\n",
    "# Merchant transaction volume\n",
    "merchant_volume = df_features.groupby('merchant').size()\n",
    "df_features['merchant_volume'] = df_features['merchant'].map(merchant_volume)\n",
    "print(\" Created: merchant_volume\")\n",
    "\n",
    "# High-risk merchant categories\n",
    "high_risk_merchants = ['Unknown Store', 'Suspicious Site', 'Foreign ATM', 'Online Store']\n",
    "df_features['is_high_risk_merchant'] = df_features['merchant'].isin(high_risk_merchants).astype(int)\n",
    "print(\" Created: is_high_risk_merchant\")\n",
    "\n",
    "# Average amount per merchant\n",
    "merchant_avg_amount = df_features.groupby('merchant')['transaction_amount'].mean()\n",
    "df_features['merchant_avg_amount'] = df_features['merchant'].map(merchant_avg_amount)\n",
    "df_features['amount_vs_merchant_avg'] = df_features['transaction_amount'] / df_features['merchant_avg_amount']\n",
    "print(\" Created: merchant_avg_amount, amount_vs_merchant_avg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09955016-e456-45f9-8e76-d90da0d55aaa",
   "metadata": {},
   "source": [
    "## Card-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9d198277-3b11-429a-8a5f-8f343419b845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CREATING CARD-BASED FEATURES\n",
      "----------------------------------------\n",
      " Created: card_provider_risk\n",
      " Created: is_premium_card\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n CREATING CARD-BASED FEATURES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Card provider risk\n",
    "card_fraud_rate = df_features.groupby('card_provider')['is_fraud'].mean()\n",
    "df_features['card_provider_risk'] = df_features['card_provider'].map(card_fraud_rate)\n",
    "print(\" Created: card_provider_risk\")\n",
    "\n",
    "# Premium card indicator\n",
    "premium_cards = ['American Express', 'Amex']\n",
    "df_features['is_premium_card'] = df_features['card_provider'].isin(premium_cards).astype(int)\n",
    "print(\" Created: is_premium_card\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904a34e-8250-4382-ba0c-c5f6e9e1a1a2",
   "metadata": {},
   "source": [
    "## Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d261749d-ead6-4350-a2f4-53bb6fabe28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATING INTERACTION FEATURES\n",
      "----------------------------------------\n",
      " Created: combined_risk_score\n",
      " Created: international_night, high_risk_merchant_night\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nCREATING INTERACTION FEATURES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# Risk score combinations\n",
    "df_features['combined_risk_score'] = (df_features['merchant_risk_score'] + \n",
    "                                    df_features['country_risk_score'] + \n",
    "                                    df_features['card_provider_risk']) / 3\n",
    "print(\" Created: combined_risk_score\")\n",
    "\n",
    "# Location × Time interaction\n",
    "df_features['international_night'] = df_features['is_international'] * df_features['is_night']\n",
    "df_features['high_risk_merchant_night'] = df_features['is_high_risk_merchant'] * df_features['is_night']\n",
    "print(\" Created: international_night, high_risk_merchant_night\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304b59e-7090-4cbc-a65f-4985b586276b",
   "metadata": {},
   "source": [
    "## ENCODING CATEGORICAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "971255cc-af59-4eb2-9294-75041d822b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ENCODING CATEGORICAL VARIABLES\n",
      "----------------------------------------\n",
      " Encoded: merchant\n",
      " Encoded: card_provider\n",
      " Encoded: country\n",
      " Encoded: state\n",
      " Encoded: city\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Label encoding for high-cardinality categorical variables\n",
    "label_encoders = {}\n",
    "categorical_cols = ['merchant', 'card_provider', 'country', 'state', 'city', 'email_domain', 'phone_area_code']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df_features.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_features[f'{col}_encoded'] = le.fit_transform(df_features[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        print(f\" Encoded: {col}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af6d9c5-3337-44e6-8168-b6582ec7beb7",
   "metadata": {},
   "source": [
    "## SCALING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "96f4478f-6bc3-474a-a79e-bd889bc035fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCALING NUMERICAL FEATURES\n",
      "----------------------------------------\n",
      " Scaled: transaction_amount\n",
      " Scaled: merchant_volume\n",
      " Scaled: merchant_avg_amount\n",
      " Scaled: amount_vs_merchant_avg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nSCALING NUMERICAL FEATURES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Features to scale\n",
    "numerical_features = ['transaction_amount', \n",
    "                     'merchant_volume', 'merchant_avg_amount', 'amount_vs_merchant_avg'\n",
    "                     ]\n",
    "\n",
    "# Standard scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_features = []\n",
    "\n",
    "for feature in numerical_features:\n",
    "    if feature in df_features.columns:\n",
    "        scaled_name = f'{feature}_scaled'\n",
    "        df_features[scaled_name] = scaler.fit_transform(df_features[[feature]])\n",
    "        scaled_features.append(scaled_name)\n",
    "        print(f\" Scaled: {feature}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c8d9a-a9ca-4acc-b2be-b5bb871591d3",
   "metadata": {},
   "source": [
    "## FINAL FEATURE SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "66958288-89c9-4a7b-a313-5d3992b90802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FEATURE ENGINEERING SUMMARY\n",
      "----------------------------------------\n",
      "Original features: 16\n",
      "Engineered features: 47\n",
      "New features created: 31\n",
      "\n",
      "Final dataset shape: (1000, 47)\n",
      "Memory usage: 0.92 MB\n",
      "\n",
      "Feature categories created:\n",
      "• Amount-based features: 8\n",
      "• Time-based features: 9\n",
      "• Location-based features: 4-6\n",
      "• Merchant-based features: 5\n",
      "• Card-based features: 4\n",
      "• User behavior features: 6\n",
      "• Interaction features: 5\n",
      "• Encoded categorical features: 7\n",
      "• Scaled features: 4\n",
      "\n",
      "Feature types:\n",
      "• Numerical: 35\n",
      "• Boolean/Binary: 12\n",
      "• Encoded: 5\n",
      "• Scaled: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nFEATURE ENGINEERING SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(f\"Original features: {df.shape[1]}\")\n",
    "print(f\"Engineered features: {df_features.shape[1]}\")\n",
    "print(f\"New features created: {df_features.shape[1] - df.shape[1]}\")\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df_features.shape}\")\n",
    "print(f\"Memory usage: {df_features.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\nFeature categories created:\")\n",
    "print(f\"• Amount-based features: 8\")\n",
    "print(f\"• Time-based features: 9\") \n",
    "print(f\"• Location-based features: 4-6\")\n",
    "print(f\"• Merchant-based features: 5\")\n",
    "print(f\"• Card-based features: 4\")\n",
    "print(f\"• User behavior features: 6\")\n",
    "print(f\"• Interaction features: 5\")\n",
    "print(f\"• Encoded categorical features: {len(categorical_cols)}\")\n",
    "print(f\"• Scaled features: {len(scaled_features)}\")\n",
    "\n",
    "# Show feature types\n",
    "feature_types = {\n",
    "    'Numerical': df_features.select_dtypes(include=[np.number]).shape[1],\n",
    "    'Boolean/Binary': len([col for col in df_features.columns if col.startswith('is_')]),\n",
    "    'Encoded': len([col for col in df_features.columns if col.endswith('_encoded')]),\n",
    "    'Scaled': len([col for col in df_features.columns if col.endswith('_scaled')])\n",
    "}\n",
    "\n",
    "print(f\"\\nFeature types:\")\n",
    "for ftype, count in feature_types.items():\n",
    "    print(f\"• {ftype}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10cc0b-7294-4c94-a0e2-158bc249451c",
   "metadata": {},
   "source": [
    "## Saving Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "79e60231-9313-4ece-8c1e-c321e0b1a21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved to: ../data/credit_card_fraud_fe_updated.csv\n"
     ]
    }
   ],
   "source": [
    "relative_path = '../data/credit_card_fraud_fe_updated.csv'\n",
    "df_features.to_csv(relative_path, index=False)\n",
    "print(f\" Saved to: {relative_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
